{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing\n",
    "\n",
    "We consider the same notebook used in the labs, containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: Insert your ID number (\"numero di matricola\") below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 2021445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data, remove data samples/points with missing values (NaN), and print some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.645240e+09</td>\n",
       "      <td>5.354358e+05</td>\n",
       "      <td>3.381163</td>\n",
       "      <td>2.071903</td>\n",
       "      <td>2070.027813</td>\n",
       "      <td>1.525054e+04</td>\n",
       "      <td>1.434893</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.244311</td>\n",
       "      <td>3.459229</td>\n",
       "      <td>7.615676</td>\n",
       "      <td>1761.252212</td>\n",
       "      <td>308.775601</td>\n",
       "      <td>1967.489254</td>\n",
       "      <td>94.668774</td>\n",
       "      <td>98077.125158</td>\n",
       "      <td>47.557868</td>\n",
       "      <td>-122.212337</td>\n",
       "      <td>1982.544564</td>\n",
       "      <td>13176.302465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.854203e+09</td>\n",
       "      <td>3.809004e+05</td>\n",
       "      <td>0.895472</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>920.251879</td>\n",
       "      <td>4.254457e+04</td>\n",
       "      <td>0.507792</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.776298</td>\n",
       "      <td>0.682592</td>\n",
       "      <td>1.166324</td>\n",
       "      <td>815.934864</td>\n",
       "      <td>458.977904</td>\n",
       "      <td>28.095275</td>\n",
       "      <td>424.439427</td>\n",
       "      <td>54.172937</td>\n",
       "      <td>0.140789</td>\n",
       "      <td>0.139577</td>\n",
       "      <td>686.256670</td>\n",
       "      <td>25413.180755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>6.490000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.177500</td>\n",
       "      <td>-122.514000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.199775e+09</td>\n",
       "      <td>3.150000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.453750e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98032.000000</td>\n",
       "      <td>47.459575</td>\n",
       "      <td>-122.324250</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>5429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.027701e+09</td>\n",
       "      <td>4.450000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1545.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98059.000000</td>\n",
       "      <td>47.572500</td>\n",
       "      <td>-122.226000</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>7873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.358175e+09</td>\n",
       "      <td>6.402500e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>1.122250e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98117.000000</td>\n",
       "      <td>47.680250</td>\n",
       "      <td>-122.124000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10408.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.839301e+09</td>\n",
       "      <td>5.350000e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8010.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6720.000000</td>\n",
       "      <td>2620.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>5790.000000</td>\n",
       "      <td>425581.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price     bedrooms    bathrooms  sqft_living  \\\n",
       "count  3.164000e+03  3.164000e+03  3164.000000  3164.000000  3164.000000   \n",
       "mean   4.645240e+09  5.354358e+05     3.381163     2.071903  2070.027813   \n",
       "std    2.854203e+09  3.809004e+05     0.895472     0.768212   920.251879   \n",
       "min    1.000102e+06  7.500000e+04     0.000000     0.000000   380.000000   \n",
       "25%    2.199775e+09  3.150000e+05     3.000000     1.500000  1430.000000   \n",
       "50%    4.027701e+09  4.450000e+05     3.000000     2.000000  1910.000000   \n",
       "75%    7.358175e+09  6.402500e+05     4.000000     2.500000  2500.000000   \n",
       "max    9.839301e+09  5.350000e+06     8.000000     6.000000  8010.000000   \n",
       "\n",
       "           sqft_lot       floors   waterfront         view    condition  \\\n",
       "count  3.164000e+03  3164.000000  3164.000000  3164.000000  3164.000000   \n",
       "mean   1.525054e+04     1.434893     0.009798     0.244311     3.459229   \n",
       "std    4.254457e+04     0.507792     0.098513     0.776298     0.682592   \n",
       "min    6.490000e+02     1.000000     0.000000     0.000000     1.000000   \n",
       "25%    5.453750e+03     1.000000     0.000000     0.000000     3.000000   \n",
       "50%    8.000000e+03     1.000000     0.000000     0.000000     3.000000   \n",
       "75%    1.122250e+04     2.000000     0.000000     0.000000     4.000000   \n",
       "max    1.651359e+06     3.500000     1.000000     4.000000     5.000000   \n",
       "\n",
       "             grade   sqft_above  sqft_basement     yr_built  yr_renovated  \\\n",
       "count  3164.000000  3164.000000    3164.000000  3164.000000   3164.000000   \n",
       "mean      7.615676  1761.252212     308.775601  1967.489254     94.668774   \n",
       "std       1.166324   815.934864     458.977904    28.095275    424.439427   \n",
       "min       3.000000   380.000000       0.000000  1900.000000      0.000000   \n",
       "25%       7.000000  1190.000000       0.000000  1950.000000      0.000000   \n",
       "50%       7.000000  1545.000000       0.000000  1969.000000      0.000000   \n",
       "75%       8.000000  2150.000000     600.000000  1990.000000      0.000000   \n",
       "max      12.000000  6720.000000    2620.000000  2015.000000   2015.000000   \n",
       "\n",
       "            zipcode          lat         long  sqft_living15     sqft_lot15  \n",
       "count   3164.000000  3164.000000  3164.000000    3164.000000    3164.000000  \n",
       "mean   98077.125158    47.557868  -122.212337    1982.544564   13176.302465  \n",
       "std       54.172937     0.140789     0.139577     686.256670   25413.180755  \n",
       "min    98001.000000    47.177500  -122.514000     620.000000     660.000000  \n",
       "25%    98032.000000    47.459575  -122.324250    1480.000000    5429.500000  \n",
       "50%    98059.000000    47.572500  -122.226000    1830.000000    7873.000000  \n",
       "75%    98117.000000    47.680250  -122.124000    2360.000000   10408.250000  \n",
       "max    98199.000000    47.777600  -121.315000    5790.000000  425581.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the feature matrix and the vector of target values. We want to predict the price by using features other than id as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data: 3164\n"
     ]
    }
   ],
   "source": [
    "Data = df.values\n",
    "# m = number of input samples\n",
    "m = Data.shape[0]\n",
    "print(\"Amount of data:\",m)\n",
    "Y = Data[:m,2]\n",
    "X = Data[:m,3:]\n",
    "\n",
    "feature_names = df.columns[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the $m$ samples of the data into 3 parts: one will be used for training and choosing the parameters, one for choosing among different models, and one for testing. The part for training and choosing the parameters will consist of $m_{train}=2/3 m$ samples, the one for choosing among different models will consist of $m_{val}= (m - m_{train})/2$ samples, while the other part consists of $m_{test}=m - m_{train} - m_{val}$ samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data for training and deciding parameters: 2109\n",
      "Amount of data for validation (choosing among different models): 527\n",
      "Amount of data for test: 528\n"
     ]
    }
   ],
   "source": [
    "# Split data into train (2/3 of samples), validation (1/6 of samples), and test data (the rest)\n",
    "m_train = int(2./3.*m)\n",
    "m_val = int((m-m_train)/2.)\n",
    "m_test = m - m_train - m_val\n",
    "print(\"Amount of data for training and deciding parameters:\",m_train)\n",
    "print(\"Amount of data for validation (choosing among different models):\",m_val)\n",
    "print(\"Amount of data for test:\",m_test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Xtrain_and_val, Ytrain_and_val is the part of data for training and validation\n",
    "#Xtest, Ytest is the part of data for testing\n",
    "Xtrain_and_val, Xtest, Ytrain_and_val, Ytest = train_test_split(X, Y, test_size=m_test/m, random_state=numero_di_matricola)\n",
    "\n",
    "#if you need to consider a specific training and validation split, use\n",
    "#Xtrain, Ytrain for training and Xval, Yval for validation\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_and_val, Ytrain_and_val, test_size=m_val/(m_train+m_val), random_state=numero_di_matricola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xtrain_and_val_scaled = scaler.transform(Xtrain_and_val)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtest_scaled = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn the best neural network with 1 hidden layer and between 1 and 9 hidden nodes, choosing the best number of hidden nodes with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    8.1s finished\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(100,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_fun=15000,\n",
       "                                    max_iter=200, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=None, shuffle=True,\n",
       "                                    solver='adam', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=False,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'activation': ['relu'],\n",
       "                         'hidden_layer_sizes': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'random_state': [2021445], 'solver': ['lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_cv = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,10)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['lbfgs'], \n",
    "              'random_state': [numero_di_matricola]\n",
    "             }\n",
    "mlp_GS = GridSearchCV(mlp_cv, param_grid=param_grid, \n",
    "                   cv=5, verbose=True)\n",
    "mlp_GS.fit(Xtrain_and_val_scaled, Ytrain_and_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check what is the best parameter, and compare the best NNs with the linear model (learned on train and validation) on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=7, learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
      "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "             power_t=0.5, random_state=2021445, shuffle=True, solver='lbfgs',\n",
      "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "             warm_start=False)\n",
      "Error (1-R^2) of best model:  0.19499652629058806\n"
     ]
    }
   ],
   "source": [
    "#let's print the best model according to grid search\n",
    "print(\"Best model: \",mlp_GS.best_estimator_)\n",
    "#let's print the error 1-R^2 for the best model\n",
    "print(\"Error (1-R^2) of best model: \",1. - mlp_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's learn the best NN using all of training and validation, and then compare the error of the best NN on train and validation and on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error best model on train and validation:  0.15640023941577474\n",
      "Error best model on test data:  0.15780180798281307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "best_mlp = MLPRegressor(hidden_layer_sizes=(6,), activation='relu', solver='lbfgs', random_state = numero_di_matricola)\n",
    "best_mlp.fit(Xtrain_and_val_scaled,Ytrain_and_val)\n",
    "\n",
    "print(\"Error best model on train and validation: \",1. - best_mlp.score(Xtrain_and_val_scaled,Ytrain_and_val))\n",
    "print(\"Error best model on test data: \",1. - best_mlp.score(Xtest_scaled,Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's learn the linear model on train and validation, and get error (1-R^2) on train and validation and on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - coefficient of determination on training data:0.2739738379137041\n",
      "1 - coefficient of determination on test data:0.32454538377939723\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "#LR the linear regression model\n",
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "#fit the model on training data\n",
    "LR.fit(Xtrain_and_val_scaled, Ytrain_and_val)\n",
    "\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - LR.score(Xtrain_and_val_scaled,Ytrain_and_val)))\n",
    "print(\"1 - coefficient of determination on test data:\"+str(1 - LR.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now explore the k-Nearest Neighbours (kNN) method for regression. In order to do this, you will need to use load the scikit-learn package *neighbors.KNeighborsRegressor* \n",
    "\n",
    "k-Nearest Neighbours for regression works as follows: the predicted value $h(\\textbf{x})$ for an instance $\\textbf{x}$ is obtained by first finding the $\\ell$ instances *in the training set* that are clostest to $\\textbf{x}$; the predicted value $h(\\textbf{x})$ is then the mean of the targets of such $\\ell$ instances. $\\ell$ is a parameter of the method. The targets of the $\\ell$ instances used for prediction can be weighted by the (inverse of) their distance to $\\textbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: load the package for kNN regression, learn the model with default parameters using the training and validation scaled data, and print the error (1-R^2) on the data used to train the model and on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training and validation data:0.1521765394969138\n",
      "Error on test data:0.334522404655212\n"
     ]
    }
   ],
   "source": [
    "#TO DO: import package\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#TO DO: learn model\n",
    "knn = KNeighborsRegressor().fit(Xtrain_and_val_scaled, Ytrain_and_val)\n",
    "\n",
    "print(\"Error on training and validation data:\"+str(1 - knn.score(Xtrain_and_val_scaled,Ytrain_and_val)))\n",
    "print(\"Error on test data:\"+str(1 - knn.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: repeat the point (including the printing instructions) above using the kNN version where points are weighted by the inverse of their distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training and validation data:0.0006495792904336328\n",
      "Error on test data:0.3315370231490401\n"
     ]
    }
   ],
   "source": [
    "#TO DO: import package\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "#TO DO: learn model \n",
    "#distance : weight points by the inverse of their distance. \n",
    "knn = KNeighborsRegressor(weights = 'distance').fit(Xtrain_and_val_scaled, Ytrain_and_val)\n",
    "\n",
    "print(\"Error on training and validation data:\"+str(1 - knn.score(Xtrain_and_val_scaled,Ytrain_and_val)))\n",
    "print(\"Error on test data:\"+str(1 - knn.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: use cross validation to choose the best number of neighbours between 2 and 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn2 = KNeighborsRegressor()\n",
    "params = {'n_neighbors': np.arange(2, 21)}\n",
    "knn_gs = GridSearchCV(knn2, params, cv=5).fit(Xtrain_and_val_scaled, Ytrain_and_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: print the best model according to cross validation above, and print the score of the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                    metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
      "                    weights='uniform')\n",
      "Score of best model:  0.7535968802115536\n"
     ]
    }
   ],
   "source": [
    "#let's print the best model according to grid search\n",
    "print(\"Best model: \", knn_gs.best_estimator_)\n",
    "#let's print the error 1-R^2 for the best model\n",
    "print(\"Score of best model: \",knn_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: learn the best model on all of the training and validation scaled data, and print the error on training and validation scaled data, and on test scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error best model on train and validation:  0.1568521666199003\n",
      "Error best model on test data:  0.3073877968909494\n"
     ]
    }
   ],
   "source": [
    "#TO DO: learn model\n",
    "knn3 = KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                    metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
    "                    weights='uniform').fit(Xtrain_and_val_scaled, Ytrain_and_val)\n",
    "\n",
    "print(\"Error best model on train and validation: \",1. - knn3.score(Xtrain_and_val_scaled,Ytrain_and_val))\n",
    "print(\"Error best model on test data: \",1. - knn3.score(Xtest_scaled,Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: compare the error on test data of the best kNN model with the error on test data of linear regression and of NNs. Describe what you observe and give a potential explanation.\n",
    "## [USE MAX 10 LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error on test data linear regression = 0.32454538377939723                                                                     \n",
    "Error on test data NN = 0.15780180798281307                                                                                     \n",
    "Error on test data kNN = 0.3073877968909494                                                                                     \n",
    "\n",
    "kNN and linear regression are easy to implement but the results are not as successful as those obtained using NN, so in many cases the best way to find the best result is to use neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and \"Local\" Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now going to explore the use of clustering to identify groups of *similar* instances, and then learning models that are specific to each group.\n",
    "\n",
    "Once you have clustered the data, and then learned a model for each cluster, the prediction for a new instance is obtained by using the model of the cluster that is the closest to the instance, where the distance of a cluster to the instance is defined as the distance of the *center* of the cluster to the instance.\n",
    "\n",
    "**Note**: in this part you are not explicitely told which part of the data to use, deciding which one is the correct one is part of the homework!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: use k-means in sklearn to learn a cluster with 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5).fit(Xtrain_and_val_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: for each cluster, learn a linear model using the elements of the cluster. For each model, print the error on the data used to learn it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X_cluster = [[],[],[],[],[]] #each list of X_cluster contains the data associated with cluster = index\n",
    "y_cluster = [[],[],[],[],[]]\n",
    "n = Xtrain_and_val_scaled.shape[0];\n",
    "for i in range(n):\n",
    "    index = kmeans.predict(Xtrain_and_val_scaled)[i]\n",
    "    X_cluster[index].append(Xtrain_and_val_scaled[i])\n",
    "    y_cluster[index].append(Ytrain_and_val[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training cluster[0] = 0.22642647465108223\n",
      "Error on training cluster[1] = 0.3710165545079471\n",
      "Error on training cluster[2] = 0.3325090068855213\n",
      "Error on training cluster[3] = 0.31229142341460125\n",
      "Error on training cluster[4] = 0.054734280385335454\n"
     ]
    }
   ],
   "source": [
    "lm = []\n",
    "for i in range(0,5):\n",
    "    lm.append(LinearRegression().fit(X_cluster[i], y_cluster[i]))\n",
    "    print(\"Error on training cluster[\"+str(i)+\"] = \"+str(1. - lm[i].score(X_cluster[i], y_cluster[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: *compute* the error (1 - R^2) on the data not used to learn the models.\n",
    "For each instance not used to learn the model, the prediction is done by:\n",
    "- finding the cluster C whose center is the closest to the instance\n",
    "- use the model learned for cluster C to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cluster_test = [[],[],[],[],[]]\n",
    "y_cluster_test = [[],[],[],[],[]]\n",
    "for i in range(Xtest_scaled.shape[0]):\n",
    "    distances = []\n",
    "    for j in range(0,5):\n",
    "         distances.append(np.linalg.norm(Xtest_scaled[i]-kmeans.cluster_centers_[j])) #Euclidean distance\n",
    "    index = distances.index(min(distances))\n",
    "    X_cluster_test[index].append(Xtest_scaled[i])\n",
    "    y_cluster_test[index].append(Ytest[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: *print* the error (1-R^2) on the data not used to learn the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on test cluster[0] = 0.1874460283946796\n",
      "Error on test cluster[1] = 0.31358063613194154\n",
      "Error on test cluster[2] = 0.2648153198557609\n",
      "Error on test cluster[3] = 0.426351816022963\n",
      "Error on test cluster[4] = 0.10349550974351973\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print(\"Error on test cluster[\"+str(i)+\"] = \"+str(1. - lm[i].score(X_cluster_test[i], y_cluster_test[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: compare the error of the model \"clustering + linear models\" and of the linear model (see the beginning of the HW). Describe what you observe, and provide a possible explanation.\n",
    "## [USE MAX 10 LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error on test data linear regression = 0.32454538377939723\n",
    "\n",
    "I notice that in the case of cluster = 3 I got a bad result because the number of samples within this cluster is too low to build a good model but in the case of cluster = 2 it is possible to see the result is better the outcome obtained by using the linear regression, this is due because the data are sufficient to produce a good model and especially the samples I used are very similar to each other (same cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: compare the error of the model \"clustering + linear models\" and of kNN. Describe what you observe, and provide a possible explanation.\n",
    "## [USE MAX 10 LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error on test data kNN = 0.3073877968909494 \n",
    "\n",
    "I have noticed that clusters 2 and 4 perform better than kNN it is also important to say that the distance calculation is computationally expensive and proportional to the size of the dataset, so this could be the cause of the high error for kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and \"Local\" NNs\n",
    "\n",
    "Repeat the same as above, but using neural networks instead of linear models.\n",
    "\n",
    "**Note**: note that we are not telling you which parameters to use for NNs. You have to decide how to select the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: clearly explain how you decided to set the parameters, motivating the choice of your strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use GridSearchCV to find the best parameters as we have done for the HW2. The best result obtained with this technique corresponds to two hidden layers with 50 neurons each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: repeat the analysis in part \"Clustering and \"Local\" Linear Models\" using NNs instead of linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR NN\n",
      "\n",
      "Best parameters set found:\n",
      "{'hidden_layer_sizes': (50, 50)}\n",
      "Score with best parameters:\n",
      "0.622922940643712\n",
      "\n",
      "All scores on the grid:\n",
      "-2.421 - {'hidden_layer_sizes': (10,)}\n",
      "-2.265 - {'hidden_layer_sizes': (50,)}\n",
      "-0.050 - {'hidden_layer_sizes': (10, 10)}\n",
      "0.623 - {'hidden_layer_sizes': (50, 50)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (3000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "hl_parameters = {'hidden_layer_sizes': [(10,), (50,), (10,10,), (50,50,)]}\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "#Increase max_iter becouse the optimization hasn't converged \n",
    "cv = KFold(n_splits=5)\n",
    "mlp_cv = MLPRegressor(max_iter=3000)\n",
    "grid = GridSearchCV(mlp_cv, hl_parameters, cv=cv)\n",
    "grid.fit(Xval_scaled.tolist(), Yval.tolist())\n",
    "\n",
    "print ('RESULTS FOR NN\\n')\n",
    "print(\"Best parameters set found:\")\n",
    "print(grid.best_params_)\n",
    "print(\"Score with best parameters:\")\n",
    "print(grid.best_score_)\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "for a,b in zip(grid.cv_results_['mean_test_score'], grid.cv_results_['params']):\n",
    "    print(\"%0.3f - %r\"% (a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Error on training cluster[0] = 0.8508240313174289\n",
      "NN Error on test cluster    [0] = 0.7415850925021548\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Error on training cluster[1] = 0.3607398907366741\n",
      "NN Error on test cluster    [1] = 0.3750387086138194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Error on training cluster[2] = 0.3581145318079466\n",
      "NN Error on test cluster    [2] = 0.31013152852642256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN Error on training cluster[3] = 0.40368722864321327\n",
      "NN Error on test cluster    [3] = 0.4492354652015865\n",
      "\n",
      "NN Error on training cluster[4] = 0.8368352680707952\n",
      "NN Error on test cluster    [4] = 0.7703618282544413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miro1\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = []\n",
    "for i in range(0,5):\n",
    "    mlp.append(MLPRegressor(hidden_layer_sizes=(50,50), max_iter=2000).fit(X_cluster[i], y_cluster[i]))\n",
    "    print(\"NN Error on training cluster[\"+str(i)+\"] = \"+str(1. - mlp[i].score(X_cluster[i], y_cluster[i])))\n",
    "    print(\"NN Error on test cluster    [\"+str(i)+\"] = \"+str(1. - mlp[i].score(X_cluster_test[i], y_cluster_test[i]))+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: compare the error of the model \"clustering + NNs\" and of NNs (see the beginning of the HW). Describe what you observe, and provide a possible explanation.\n",
    "## [USE MAX 10 LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error on test data NN = 0.15780180798281307\n",
    "\n",
    "In this situation the results of the clusters are all worse than the NNs this is caused because the number of samples within each cluster is not enough to obtain a good model, so we are in a condition of undercutting (Cluster = 3/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: compare the error of the model \"clustering + NNs\" and of kNN. Describe what you observe, and provide a possible explanation.\n",
    "## [USE MAX 10 LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data error kNN = 0.3073877968909494\n",
    "\n",
    "As before, the result of calculating the distance kNN is computationally expensive and proportional to the size of the dataset, however in general clusters perform worse because the neural network requires a lot of input data for good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: compare the error of the model \"clustering + NNs\" and of \"clustering + Linear Models\". Describe what you observe, and provide a possible explanation.\n",
    "## [USE MAX 10 LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression error of test data = 0.32454538377939723\n",
    "\n",
    "I notice that in the case of cluster = 3/4 I got a negative result because the number of samples within this cluster is too low to build a good model however for the first three models, compared to linear regression, the results are very close. It is also possible to see that the test error is less than the training error, usually this happens when a method generalizes well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
